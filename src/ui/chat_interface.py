# src/ui/chat_interface.py
import streamlit as st
from src.services.chroma_service import search_similar_documents
from src.services.intent_detector import extract_contact_intent
from src.models.gemini_client import GeminiClient
from src.config.settings import GEMINI_API_KEY, MAX_RESPONSE_WORDS
from src.utils.session_manager import SessionStateManager
from src.utils.validators import sanitize_input

def generate_contextual_response(query, context_documents):
    """Generar respuesta contextual con lÃ­mite de palabras"""
    try:
        client = GeminiClient(GEMINI_API_KEY)
        if not client.model:
            return "ğŸ”§ El modelo no estÃ¡ disponible.", None
        
        # Si hay muchos documentos, resumir contexto para ahorrar tokens
        if context_documents:
            # Tomar solo los 3 mÃ¡s relevantes y resumirlos si son muy largos
            context = "\n\n".join(context_documents[:3])
            if len(context.split()) > 300:
                context = " ".join(context.split()[:300]) + "..."
            
            prompt = f"""Eres un experto vendedor de ESET. Usa esta informaciÃ³n:

{context}

Pregunta: {query}

Responde como un vendedor profesional."""
        else:
            prompt = f"""Eres un vendedor experto de ESET. Responde a esta pregunta:

Pregunta: {query}

Respuesta:"""
        
        # Llamar con lÃ­mite de palabras configurable
        response, _ = client.generate_content(prompt, max_words=MAX_RESPONSE_WORDS)
        
        return response
    except Exception as e:
        st.sidebar.error(f"âŒ Error generando respuesta: {e}")
        return "âš ï¸ Error temporal. Por favor, intenta nuevamente."

def procesar_mensaje(prompt):
    """Procesar un mensaje del usuario con detecciÃ³n de 2 niveles"""
    # Sanitizar entrada
    prompt = sanitize_input(prompt)
    st.session_state.last_query = prompt
    SessionStateManager.add_message("user", prompt)
    
    # Detectar intenciÃ³n con 2 niveles
    intencion = extract_contact_intent(prompt)
    
    if intencion == "DIRECTO":
        # ACTIVA FORMULARIO DIRECTAMENTE
        contact_response = """Â¡Perfecto! Para ofrecerte la mejor atenciÃ³n personalizada, completa este formulario.

Un especialista te contactarÃ¡ en menos de 24 horas para:
- âœ… Analizar tus necesidades especÃ­ficas
- âœ… Proporcionarte una demostraciÃ³n personalizada
- âœ… Entregarte una cotizaciÃ³n detallada

ğŸ‘‡ Completa el formulario a continuaciÃ³n:"""
        
        SessionStateManager.add_message("assistant", contact_response)
        st.session_state.awaiting_form = True
        return contact_response
        
    elif intencion == "SUGERENCIA":
        # SUGIERE contacto pero no fuerza
        suggestion_response = """Â¡Me alegra que estÃ©s interesado! 

Para ofrecerte informaciÃ³n mÃ¡s detallada y una cotizaciÃ³n personalizada, puedo conectarte con uno de nuestros especialistas.

ğŸ’¡ **Â¿QuerÃ©s que te contactemos?** Simplemente escribÃ­: *"quiero dejar mis datos"* y te ayudo con el proceso.

Â¿En quÃ© mÃ¡s puedo ayudarte mientras tanto?"""
        
        SessionStateManager.add_message("assistant", suggestion_response)
        return suggestion_response
    
    else:
        # Sin intenciÃ³n detectada â†’ bÃºsqueda normal en documentos
        with st.spinner("Buscando informaciÃ³n..."):
            relevant_docs = search_similar_documents(prompt, top_k=3)
            response = generate_contextual_response(prompt, relevant_docs)
            
            SessionStateManager.add_message("assistant", response)
            
            # Sugerir contacto solo si es relevante
            if any(word in prompt.lower() for word in ['precio', 'cotiz', 'comprar']):
                response += "\n\nğŸ’¡ **Â¿CotizaciÃ³n?** Escribe 'quiero dejar mis datos'."
            
            return response
